{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b61685ba",
      "metadata": {
        "id": "b61685ba"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import string\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "import gensim\n",
        "from gensim.models import Word2Vec, KeyedVectors\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6a8c68c",
      "metadata": {
        "id": "c6a8c68c"
      },
      "outputs": [],
      "source": [
        "#text preprocessing\n",
        "reviews = pd.read_csv(\"imdbReviews.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a494c3f9",
      "metadata": {
        "id": "a494c3f9",
        "outputId": "856bfdde-d660-4032-8ed0-aada68b6dd87"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Index</th>\n",
              "      <th>URL</th>\n",
              "      <th>Text</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3617</td>\n",
              "      <td>http://www.imdb.com/title/tt0210075/usercomments</td>\n",
              "      <td>Girlfight follows a project dwelling New York ...</td>\n",
              "      <td>POS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3671</td>\n",
              "      <td>http://www.imdb.com/title/tt0337640/usercomments</td>\n",
              "      <td>Hollywood North is an euphemism from the movie...</td>\n",
              "      <td>POS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3157</td>\n",
              "      <td>http://www.imdb.com/title/tt0303549/usercomments</td>\n",
              "      <td>That '70s Show is definitely the funniest show...</td>\n",
              "      <td>POS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>660</td>\n",
              "      <td>http://www.imdb.com/title/tt0716825/usercomments</td>\n",
              "      <td>9/10- 30 minutes of pure holiday terror. Okay,...</td>\n",
              "      <td>POS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>265</td>\n",
              "      <td>http://www.imdb.com/title/tt0182225/usercomments</td>\n",
              "      <td>A series of random, seemingly insignificant th...</td>\n",
              "      <td>POS</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Index                                               URL  \\\n",
              "0   3617  http://www.imdb.com/title/tt0210075/usercomments   \n",
              "1   3671  http://www.imdb.com/title/tt0337640/usercomments   \n",
              "2   3157  http://www.imdb.com/title/tt0303549/usercomments   \n",
              "3    660  http://www.imdb.com/title/tt0716825/usercomments   \n",
              "4    265  http://www.imdb.com/title/tt0182225/usercomments   \n",
              "\n",
              "                                                Text Sentiment  \n",
              "0  Girlfight follows a project dwelling New York ...       POS  \n",
              "1  Hollywood North is an euphemism from the movie...       POS  \n",
              "2  That '70s Show is definitely the funniest show...       POS  \n",
              "3  9/10- 30 minutes of pure holiday terror. Okay,...       POS  \n",
              "4  A series of random, seemingly insignificant th...       POS  "
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "reviews.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17635c62",
      "metadata": {
        "id": "17635c62",
        "outputId": "9c5aa776-86fe-4980-816c-4b4bea3cf430"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "POS    1000\n",
              "NEG    1000\n",
              "Name: Sentiment, dtype: int64"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "reviews['Sentiment'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f36446a",
      "metadata": {
        "id": "6f36446a",
        "outputId": "3820ba06-f2e2-48e6-eae5-4c80364f1fcc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1 1 1 1 1 1 1 1 1 1]\n",
            "0    POS\n",
            "1    POS\n",
            "2    POS\n",
            "3    POS\n",
            "4    POS\n",
            "5    POS\n",
            "6    POS\n",
            "7    POS\n",
            "8    POS\n",
            "9    POS\n",
            "Name: Sentiment, dtype: object\n"
          ]
        }
      ],
      "source": [
        "#save the labels and encode them as 1 and 0 for future classification/clustering\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "enc = LabelEncoder()\n",
        "label = enc.fit_transform(reviews['Sentiment'])\n",
        "print(label[:10])\n",
        "print(reviews['Sentiment'][:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c7b1ce4",
      "metadata": {
        "id": "8c7b1ce4"
      },
      "outputs": [],
      "source": [
        "#change the text column datatype to string\n",
        "reviews = reviews.astype({'Text':'string'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6587ec93",
      "metadata": {
        "id": "6587ec93"
      },
      "outputs": [],
      "source": [
        "#get the review text for preprocessing\n",
        "text = reviews['Text']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c483b8d1",
      "metadata": {
        "id": "c483b8d1"
      },
      "outputs": [],
      "source": [
        "text1 = []\n",
        "\n",
        "for review in text:\n",
        "    #print(sentence)\n",
        "    #remove punctuation\n",
        "    review = review.translate(str.maketrans('', '', string.punctuation))\n",
        "    # remove digits/numbers\n",
        "    review = review.translate(str.maketrans('', '', string.digits))\n",
        "    #change to lowercase\n",
        "    review = review.lower()\n",
        "    #print(sentence)\n",
        "    text1.append(review)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8756f2e",
      "metadata": {
        "id": "f8756f2e"
      },
      "outputs": [],
      "source": [
        "text1 = pd.Series(text1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "282922b1",
      "metadata": {
        "id": "282922b1",
        "outputId": "f89badfc-754e-40a9-aabf-406a4477f742"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    girlfight follows project dwelling new york hi...\n",
              "1    hollywood north euphemism movie industry went ...\n",
              "2    show definitely funniest show currently tv sta...\n",
              "3    minutes pure holiday terror okay scary sure fu...\n",
              "4    series random seemingly insignificant thefts s...\n",
              "dtype: object"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#remove stop words\n",
        "\n",
        "#Setting English stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "text1 = text1.apply(lambda x: ' '.join(term for term in x.split() if term not in stop_words))\n",
        "text1[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63d385c6",
      "metadata": {
        "id": "63d385c6"
      },
      "outputs": [],
      "source": [
        "#apply stemming\n",
        "ps = nltk.PorterStemmer()\n",
        "\n",
        "text1 = text1.apply(lambda x: ' '.join(ps.stem(term) for term in x.split()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36ddab13",
      "metadata": {
        "id": "36ddab13"
      },
      "outputs": [],
      "source": [
        "reviews1 = list(zip(text1, label))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7cd2b5f",
      "metadata": {
        "id": "f7cd2b5f"
      },
      "outputs": [],
      "source": [
        "reviewsP = pd.DataFrame (reviews1, columns = ['Review', 'Sentiment'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dfae8e23",
      "metadata": {
        "id": "dfae8e23"
      },
      "outputs": [],
      "source": [
        "reviewsP1 = reviewsP.sample(frac=1, random_state=1).reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60b0b1a6",
      "metadata": {
        "id": "60b0b1a6",
        "outputId": "b27b167a-6e2e-4812-86e3-838894b04da9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1400,) (1400,)\n",
            "(600,) (600,)\n"
          ]
        }
      ],
      "source": [
        "#split the dataset\n",
        "\n",
        "#train dataset by splitting the data\n",
        "train_reviews = reviewsP1.Review[:1400]\n",
        "train_sentiments = reviewsP1.Sentiment[:1400]\n",
        "\n",
        "#test dataset\n",
        "test_reviews = reviewsP1.Review[1400:]\n",
        "test_sentiments = reviewsP1.Sentiment[1400:]\n",
        "\n",
        "print(train_reviews.shape,train_sentiments.shape)\n",
        "print(test_reviews.shape,test_sentiments.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d4304ec",
      "metadata": {
        "id": "9d4304ec",
        "outputId": "8802ca54-2105-4569-f271-e81e926ca029"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    superb episod one best season right horror cha...\n",
              "1    metamorphosi work way chill classic movi pack ...\n",
              "2    spoil lame south border adventur movi someth b...\n",
              "3    actual stop dont get wrong love bad monster mo...\n",
              "4    intent director film quit honor histori produc...\n",
              "Name: Review, dtype: object"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_reviews.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8b066e3",
      "metadata": {
        "id": "d8b066e3"
      },
      "outputs": [],
      "source": [
        "#tokenise the data\n",
        "tokenized_reviews = train_reviews.apply(lambda x: x.split())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3bb2841",
      "metadata": {
        "id": "a3bb2841"
      },
      "outputs": [],
      "source": [
        "#learn vectors from the data\n",
        "model = gensim.models.Word2Vec(\n",
        "            tokenized_reviews,\n",
        "            vector_size=100, # desired no. of features/independent variables\n",
        "            window=5,        # context window size\n",
        "            min_count=2,     # Ignores all words with total frequency lower than 2.\n",
        "            sg = 1,          # 1 for skip-gram model\n",
        "            hs = 0,\n",
        "            negative = 10,   # for negative sampling\n",
        "            workers= 32,     # no.of cores\n",
        "            seed = 34\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f56a5fc4",
      "metadata": {
        "id": "f56a5fc4",
        "outputId": "fd7b3a92-8952-4872-e7bd-8defcff098de"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3344882, 3767020)"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.train(tokenized_reviews, total_examples= len(train_reviews), epochs=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2847b43e",
      "metadata": {
        "id": "2847b43e"
      },
      "outputs": [],
      "source": [
        "embeddingsSize=100\n",
        "\n",
        "def getVectors(dataset):\n",
        "  singleDataItemEmbedding=np.zeros(embeddingsSize)\n",
        "  vectors=[]\n",
        "  for dataItem in dataset:\n",
        "    wordCount=0\n",
        "    for word in dataItem:\n",
        "      if word in model.wv:\n",
        "        singleDataItemEmbedding=singleDataItemEmbedding+model.wv.key_to_index[word]\n",
        "        wordCount=wordCount+1\n",
        "\n",
        "    singleDataItemEmbedding=singleDataItemEmbedding/wordCount\n",
        "    vectors.append(singleDataItemEmbedding)\n",
        "  return vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69453170",
      "metadata": {
        "id": "69453170"
      },
      "outputs": [],
      "source": [
        "trainReviewVectors=getVectors(train_reviews)\n",
        "testReviewVectors=getVectors(test_reviews)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67cde37d",
      "metadata": {
        "id": "67cde37d",
        "outputId": "8327828c-bd66-4d6d-d6d3-93f8c90d0ff6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[163 143]\n",
            " [141 153]] \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Positive       0.54      0.53      0.53       306\n",
            "    Negative       0.52      0.52      0.52       294\n",
            "\n",
            "    accuracy                           0.53       600\n",
            "   macro avg       0.53      0.53      0.53       600\n",
            "weighted avg       0.53      0.53      0.53       600\n",
            "\n"
          ]
        }
      ],
      "source": [
        "############################################\n",
        "###           Decision Tree              ###\n",
        "############################################\n",
        "#training the model\n",
        "DT=DecisionTreeClassifier(criterion ='entropy', random_state= 0)\n",
        "\n",
        "DT=DT.fit(trainReviewVectors,train_sentiments)\n",
        "\n",
        "DT_predict=DT.predict(testReviewVectors)\n",
        "\n",
        "\n",
        "DT_report=classification_report(test_sentiments,DT_predict,target_names=['Positive','Negative'])\n",
        "print(confusion_matrix(test_sentiments,DT_predict), '\\n')\n",
        "print(DT_report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc8391c3",
      "metadata": {
        "id": "fc8391c3"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}