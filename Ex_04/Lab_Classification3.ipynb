{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "18196a43",
   "metadata": {
    "executionInfo": {
     "elapsed": 339,
     "status": "ok",
     "timestamp": 1754814448560,
     "user": {
      "displayName": "Atefeh Khazaei",
      "userId": "14757549683264405732"
     },
     "user_tz": -60
    },
    "id": "18196a43"
   },
   "outputs": [],
   "source": [
    "import numpy as np               # used for multidimensional arrays\n",
    "import pandas as pd              # used for import the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e47f9230",
   "metadata": {
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1754814448568,
     "user": {
      "displayName": "Atefeh Khazaei",
      "userId": "14757549683264405732"
     },
     "user_tz": -60
    },
    "id": "e47f9230"
   },
   "outputs": [],
   "source": [
    "adult = pd.read_csv(\"adult_num.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddb2a82",
   "metadata": {},
   "source": [
    "Define the predittor and target attributes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9e393d19",
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1754814448575,
     "user": {
      "displayName": "Atefeh Khazaei",
      "userId": "14757549683264405732"
     },
     "user_tz": -60
    },
    "id": "9e393d19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of rows: 32561\n",
      "Number of rows after removing rare classes: 32559\n"
     ]
    }
   ],
   "source": [
    "value_counts = adult['age'].value_counts()\n",
    "# Get the ages (classes) that appear only once\n",
    "to_remove = value_counts[value_counts == 1].index\n",
    "adult_filtered = adult[~adult['age'].isin(to_remove)]\n",
    "print(f\"Original number of rows: {len(adult)}\")\n",
    "print(f\"Number of rows after removing rare classes: {len(adult_filtered)}\")\n",
    "X = adult_filtered.drop(\"income\", axis=1)\n",
    "y = adult_filtered['income']\n",
    "\n",
    "\n",
    "# âœ… Step 3: Now, split the data using stratification. It will work.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52364db0",
   "metadata": {
    "executionInfo": {
     "elapsed": 893,
     "status": "ok",
     "timestamp": 1754814449482,
     "user": {
      "displayName": "Atefeh Khazaei",
      "userId": "14757549683264405732"
     },
     "user_tz": -60
    },
    "id": "52364db0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1ffeb190",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1116,
     "status": "ok",
     "timestamp": 1754814450601,
     "user": {
      "displayName": "Atefeh Khazaei",
      "userId": "14757549683264405732"
     },
     "user_tz": -60
    },
    "id": "1ffeb190",
    "outputId": "3f155efd-c929-4582-806a-cc146ad9fcf9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[67 24  3 ...  0  0  0]\n",
      " [39 32 15 ...  0  0  0]\n",
      " [ 6 18 38 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 0  0  1 ...  0  0  0]] \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          17       0.47      0.68      0.56        99\n",
      "          18       0.22      0.23      0.22       138\n",
      "          19       0.16      0.21      0.18       178\n",
      "          20       0.13      0.17      0.15       188\n",
      "          21       0.07      0.08      0.08       180\n",
      "          22       0.07      0.09      0.08       191\n",
      "          23       0.06      0.07      0.07       219\n",
      "          24       0.05      0.06      0.05       200\n",
      "          25       0.06      0.08      0.07       210\n",
      "          26       0.06      0.08      0.07       196\n",
      "          27       0.04      0.05      0.05       209\n",
      "          28       0.04      0.05      0.05       217\n",
      "          29       0.04      0.04      0.04       203\n",
      "          30       0.03      0.03      0.03       215\n",
      "          31       0.03      0.03      0.03       222\n",
      "          32       0.03      0.04      0.04       207\n",
      "          33       0.03      0.03      0.03       219\n",
      "          34       0.04      0.04      0.04       222\n",
      "          35       0.02      0.02      0.02       219\n",
      "          36       0.02      0.02      0.02       225\n",
      "          37       0.03      0.04      0.04       215\n",
      "          38       0.04      0.04      0.04       207\n",
      "          39       0.02      0.01      0.01       204\n",
      "          40       0.02      0.02      0.02       199\n",
      "          41       0.04      0.03      0.04       202\n",
      "          42       0.01      0.01      0.01       195\n",
      "          43       0.02      0.02      0.02       193\n",
      "          44       0.03      0.02      0.02       181\n",
      "          45       0.04      0.03      0.04       184\n",
      "          46       0.03      0.02      0.02       184\n",
      "          47       0.02      0.02      0.02       177\n",
      "          48       0.04      0.03      0.03       136\n",
      "          49       0.03      0.03      0.03       144\n",
      "          50       0.03      0.03      0.03       151\n",
      "          51       0.01      0.01      0.01       149\n",
      "          52       0.03      0.03      0.03       120\n",
      "          53       0.03      0.03      0.03       116\n",
      "          54       0.03      0.02      0.02       104\n",
      "          55       0.07      0.04      0.05       105\n",
      "          56       0.00      0.00      0.00        91\n",
      "          57       0.04      0.02      0.03        89\n",
      "          58       0.00      0.00      0.00        91\n",
      "          59       0.00      0.00      0.00        89\n",
      "          60       0.00      0.00      0.00        78\n",
      "          61       0.06      0.04      0.05        75\n",
      "          62       0.03      0.02      0.02        64\n",
      "          63       0.00      0.00      0.00        57\n",
      "          64       0.07      0.06      0.06        52\n",
      "          65       0.05      0.05      0.05        44\n",
      "          66       0.00      0.00      0.00        37\n",
      "          67       0.00      0.00      0.00        38\n",
      "          68       0.00      0.00      0.00        30\n",
      "          69       0.00      0.00      0.00        27\n",
      "          70       0.00      0.00      0.00        22\n",
      "          71       0.00      0.00      0.00        18\n",
      "          72       0.00      0.00      0.00        17\n",
      "          73       0.00      0.00      0.00        16\n",
      "          74       0.00      0.00      0.00        13\n",
      "          75       0.00      0.00      0.00        11\n",
      "          76       0.00      0.00      0.00        11\n",
      "          77       0.00      0.00      0.00         7\n",
      "          78       0.00      0.00      0.00         6\n",
      "          79       0.00      0.00      0.00         5\n",
      "          80       0.00      0.00      0.00         5\n",
      "          81       0.00      0.00      0.00         5\n",
      "          82       0.00      0.00      0.00         3\n",
      "          83       0.00      0.00      0.00         1\n",
      "          84       0.00      0.00      0.00         2\n",
      "          85       0.00      0.00      0.00         1\n",
      "          88       0.00      0.00      0.00         1\n",
      "          90       0.00      0.00      0.00        11\n",
      "\n",
      "    accuracy                           0.05      8140\n",
      "   macro avg       0.03      0.04      0.04      8140\n",
      "weighted avg       0.05      0.05      0.05      8140\n",
      "\n",
      "Accuracy: 0.05245700245700246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\frank\\.conda\\envs\\py311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\frank\\.conda\\envs\\py311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\frank\\.conda\\envs\\py311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "###################\n",
    "###   Bagging   ###\n",
    "###################\n",
    "\n",
    "#import bagging\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "#import classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#initialise classifier\n",
    "#default is Decision tree\n",
    "#BC = BaggingClassifier(estimator=SVC(), n_estimators=10, random_state=0)\n",
    "#BC = BaggingClassifier(estimator=KNeighborsClassifier(n_neighbors=5), n_estimators=10, random_state=0)\n",
    "#BC = BaggingClassifier(estimator=GaussianNB(), n_estimators=10, random_state=0)\n",
    "BC = BaggingClassifier(n_estimators=10, random_state=0)   # 10 just used for easiness, you can try other number. \n",
    "\n",
    "#fit the classifier to the data\n",
    "BC.fit(X_train, y_train)\n",
    "\n",
    "#predict the values for the test set\n",
    "y_pred = BC.predict(X_test)\n",
    "\n",
    "#performance metrics\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred), '\\n')\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "# print(\"AUC:\", roc_auc_score(y_test, y_pred))  # if data is binary , use AUC to evaluate \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1860668b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[78  1  0 ...  1  0  0]\n",
      " [57  4  1 ...  5  6  0]\n",
      " [ 9  2  0 ...  9 12  0]\n",
      " ...\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  1  0]\n",
      " [ 1  0  0 ...  0  2  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          17       0.39      0.79      0.52        99\n",
      "          18       0.33      0.03      0.05       138\n",
      "          19       0.00      0.00      0.00       178\n",
      "          20       0.10      0.09      0.09       188\n",
      "          21       0.00      0.00      0.00       180\n",
      "          22       0.05      0.01      0.01       191\n",
      "          23       0.05      0.08      0.06       219\n",
      "          24       0.00      0.00      0.00       200\n",
      "          25       0.03      0.00      0.01       210\n",
      "          26       0.50      0.01      0.02       196\n",
      "          27       0.00      0.00      0.00       209\n",
      "          28       0.00      0.00      0.00       217\n",
      "          29       0.00      0.00      0.00       203\n",
      "          30       0.00      0.00      0.00       215\n",
      "          31       0.00      0.00      0.00       222\n",
      "          32       0.00      0.00      0.00       207\n",
      "          33       0.00      0.00      0.00       219\n",
      "          34       0.05      0.01      0.02       222\n",
      "          35       0.05      0.05      0.05       219\n",
      "          36       0.00      0.00      0.00       225\n",
      "          37       0.00      0.00      0.00       215\n",
      "          38       0.00      0.00      0.00       207\n",
      "          39       0.00      0.00      0.00       204\n",
      "          40       0.00      0.00      0.00       199\n",
      "          41       0.07      0.00      0.01       202\n",
      "          42       0.00      0.00      0.00       195\n",
      "          43       0.00      0.00      0.00       193\n",
      "          44       0.00      0.00      0.00       181\n",
      "          45       0.12      0.02      0.04       184\n",
      "          46       0.00      0.00      0.00       184\n",
      "          47       0.00      0.00      0.00       177\n",
      "          48       0.00      0.00      0.00       136\n",
      "          49       0.00      0.00      0.00       144\n",
      "          50       0.03      0.01      0.01       151\n",
      "          51       0.00      0.00      0.00       149\n",
      "          52       0.00      0.00      0.00       120\n",
      "          53       0.00      0.00      0.00       116\n",
      "          54       0.00      0.00      0.00       104\n",
      "          55       0.00      0.00      0.00       105\n",
      "          56       0.00      0.00      0.00        91\n",
      "          57       0.00      0.00      0.00        89\n",
      "          58       0.00      0.00      0.00        91\n",
      "          59       0.00      0.00      0.00        89\n",
      "          60       0.00      0.00      0.00        78\n",
      "          61       0.00      0.00      0.00        75\n",
      "          62       0.00      0.00      0.00        64\n",
      "          63       0.00      0.00      0.00        57\n",
      "          64       0.00      0.00      0.00        52\n",
      "          65       0.00      0.00      0.00        44\n",
      "          66       0.00      0.00      0.00        37\n",
      "          67       0.00      0.00      0.00        38\n",
      "          68       0.00      0.00      0.00        30\n",
      "          69       0.00      0.00      0.00        27\n",
      "          70       0.00      0.00      0.00        22\n",
      "          71       0.00      0.00      0.00        18\n",
      "          72       0.00      0.00      0.00        17\n",
      "          73       0.00      0.00      0.00        16\n",
      "          74       0.00      0.00      0.00        13\n",
      "          75       0.00      0.00      0.00        11\n",
      "          76       0.00      0.00      0.00        11\n",
      "          77       0.00      0.00      0.00         7\n",
      "          78       0.00      0.00      0.00         6\n",
      "          79       0.00      0.20      0.00         5\n",
      "          80       0.00      0.00      0.00         5\n",
      "          81       0.00      0.00      0.00         5\n",
      "          82       0.00      0.00      0.00         3\n",
      "          83       0.00      0.00      0.00         1\n",
      "          84       0.00      1.00      0.00         2\n",
      "          85       0.00      0.00      0.00         1\n",
      "          88       0.00      1.00      0.00         1\n",
      "          90       0.00      0.00      0.00        11\n",
      "\n",
      "    accuracy                           0.02      8140\n",
      "   macro avg       0.02      0.05      0.01      8140\n",
      "weighted avg       0.04      0.02      0.01      8140\n",
      "\n",
      "Accuracy: 0.017321867321867322\n",
      "AUC:  0.5269362562298436\n"
     ]
    }
   ],
   "source": [
    "# But if the data you are going to prediect is not binary, you should use ( multi_class= type) here \n",
    "NB = GaussianNB()\n",
    "NB.fit(X_train, y_train)\n",
    "y_pred = NB.predict(X_test)\n",
    "y_pred_proba = NB.predict_proba(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred, zero_division=0))\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "\n",
    "# This line will now work correctly\n",
    "print('AUC: ', roc_auc_score(y_test, y_pred_proba, multi_class='ovr'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "04f156ae",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3240,
     "status": "ok",
     "timestamp": 1754814453843,
     "user": {
      "displayName": "Atefeh Khazaei",
      "userId": "14757549683264405732"
     },
     "user_tz": -60
    },
    "id": "04f156ae",
    "outputId": "25232681-643d-4973-a113-a64bd102b2cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5780  400]\n",
      " [ 745 1215]] \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.91      6180\n",
      "           1       0.75      0.62      0.68      1960\n",
      "\n",
      "    accuracy                           0.86      8140\n",
      "   macro avg       0.82      0.78      0.79      8140\n",
      "weighted avg       0.85      0.86      0.85      8140\n",
      "\n",
      "Accuracy: 0.8593366093366094\n",
      "AUC: 0.7775865200449112\n"
     ]
    }
   ],
   "source": [
    "######################################\n",
    "###         Random Forest          ###\n",
    "######################################\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#initialise classifier\n",
    "#RF = RandomForestClassifier(max_depth=10, random_state=0)\n",
    "RF = RandomForestClassifier(random_state=0)\n",
    "\n",
    "#fit the classifier to the data\n",
    "RF.fit(X_train, y_train)\n",
    "\n",
    "#predict the values for the test set\n",
    "y_pred = RF.predict(X_test)\n",
    "\n",
    "#performance metrics\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred), '\\n')\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"AUC:\", roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "35f36c79",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2353,
     "status": "ok",
     "timestamp": 1754814456206,
     "user": {
      "displayName": "Atefeh Khazaei",
      "userId": "14757549683264405732"
     },
     "user_tz": -60
    },
    "id": "35f36c79",
    "outputId": "4f19d472-30c7-43f7-d397-74e20251c3ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2701    0]\n",
      " [   0 5440]] \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2701\n",
      "           1       1.00      1.00      1.00      5440\n",
      "\n",
      "    accuracy                           1.00      8141\n",
      "   macro avg       1.00      1.00      1.00      8141\n",
      "weighted avg       1.00      1.00      1.00      8141\n",
      "\n",
      "Accuracy: 1.0\n",
      "AUC: 1.0\n"
     ]
    }
   ],
   "source": [
    "###################\n",
    "###   Boosting   ###\n",
    "###################\n",
    "\n",
    "#import adaboost\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "#import classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#initialise classifier\n",
    "#default is Decision Tree\n",
    "AB = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
    "#AB = AdaBoostClassifier(estimator=GaussianNB(), n_estimators=100, random_state=0)\n",
    "#AB = AdaBoostClassifier(estimator=SVC(probability=True, kernel = 'linear'), n_estimators=100, random_state=0)\n",
    "\n",
    "#fit the classifier to the data\n",
    "AB.fit(X_train, y_train)\n",
    "\n",
    "#predict the values for the test set\n",
    "y_pred = AB.predict(X_test)\n",
    "\n",
    "#performance metrics\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred), '\\n')\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"AUC:\", roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "i-1fzdy1Egdb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 37639,
     "status": "ok",
     "timestamp": 1754814493849,
     "user": {
      "displayName": "Atefeh Khazaei",
      "userId": "14757549683264405732"
     },
     "user_tz": -60
    },
    "id": "i-1fzdy1Egdb",
    "outputId": "afea589c-b700-4116-ce66-5e0e8dd0e9a8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\frank\\.conda\\envs\\py311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 10000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=10000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\frank\\.conda\\envs\\py311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 10000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=10000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\frank\\.conda\\envs\\py311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 10000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=10000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\frank\\.conda\\envs\\py311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 10000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=10000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\frank\\.conda\\envs\\py311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 10000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=10000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\frank\\.conda\\envs\\py311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 10000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=10000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5767  392]\n",
      " [ 940 1042]] \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.94      0.90      6159\n",
      "           1       0.73      0.53      0.61      1982\n",
      "\n",
      "    accuracy                           0.84      8141\n",
      "   macro avg       0.79      0.73      0.75      8141\n",
      "weighted avg       0.83      0.84      0.83      8141\n",
      "\n",
      "Accuracy: 0.8363837366416902\n",
      "AUC: 0.7310424441830673\n"
     ]
    }
   ],
   "source": [
    "###################\n",
    "###   Stacking   ###\n",
    "###################\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "\n",
    "# Define base learners\n",
    "base_learners = [\n",
    "    ('lr', LogisticRegression(max_iter=10000)),\n",
    "    ('dt', DecisionTreeClassifier(random_state=42)),\n",
    "    ('knn', KNeighborsClassifier())\n",
    "]\n",
    "\n",
    "# Define meta-learner\n",
    "meta_learner = LogisticRegression(max_iter=10000)\n",
    "\n",
    "# Create stacking classifier\n",
    "stacking_model = StackingClassifier(\n",
    "    estimators=base_learners,\n",
    "    final_estimator=meta_learner,\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "# Train stacking model\n",
    "stacking_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = stacking_model.predict(X_test)\n",
    "\n",
    "\n",
    "#performance metrics\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred), '\\n')\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"AUC:\", roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab319516",
   "metadata": {},
   "source": [
    "## Exercise (part9) \n",
    "\n",
    "Lets remove some attributes to see if the result's accuracy remains or changes. \n",
    "\n",
    "For simplicity, lets remove the first elements of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ca8c5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
